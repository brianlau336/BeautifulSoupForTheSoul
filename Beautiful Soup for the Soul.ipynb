{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1> \n",
    "    <img src=\"https://www.numberedart.com/ekmps/shops/numberedart/images/cool-andy-warhol-x22-campbells-soup-x22-pop-art-paint-by-number-kit-378-p.jpg\" alt=\"\" width=\"50\"/>\n",
    "    <b>Beautiful Soup For The Soul</b>\n",
    "    <img src=\"https://www.numberedart.com/ekmps/shops/numberedart/images/cool-andy-warhol-x22-campbells-soup-x22-pop-art-paint-by-number-kit-378-p.jpg\" alt=\"\" width=\"50\"/>\n",
    "</h1> \n",
    "<hr>\n",
    "\n",
    "<h2> Introduction </h2><hr>\n",
    "So I heard you're looking for some data?  Well, you've come to the right place. \n",
    "\n",
    "But what do you do when the data you need doesn't come wrapped in a neat API?  Or that dataset doesn't have a \"download as csv\" button?  Inconcievable!  But never fear, web scraping is here!  \n",
    "\n",
    "<br>\n",
    "Web scraping is exactly what it sounds like: extracting data from websites.  But before we delve into Beautiful Soup, the web scraping library for Python, we have to take a step back and re-visit the good 'ole Myspace days editing HTML to make that perfect layout.  So strap in, and let's take a look at some basic HTML.\n",
    "\n",
    "![](https://github.com/brianlau336/BeautifulSoupForTheSoul/blob/master/pic1.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<h2> \n",
    "    <img src=\"https://image.flaticon.com/icons/svg/136/136528.svg\" alt=\"\" width=\"50\"/>\n",
    "    HTML\n",
    "</h2>\n",
    "<hr>\n",
    "HTML is the standard markup language for creating web pages and web applications.  HTML is <b>not</b> a programming language, like Python â€” instead, it's a markup language that tells a browser how to display content. HTML is versy similar to programs like Microsoft Word where you can make text bold, create paragraphs, etc.\n",
    "\n",
    "HTML consists of elements called tags. The most basic tag is the `<html>` tag. This tag tells the web browser that everything between the two tags can be expected to be HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.chase.com\" id=\"banking\">Bank with Chase!</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3>Tag Genealogy:</h3>\n",
    "    \n",
    "<b>child</b> â€” a child is a tag inside another tag<br>\n",
    "<b>parent</b> â€” a parent is the tag another tag is inside<br>\n",
    "<b>sibling</b> â€” a sibiling is a tag that is nested inside the same parent as another tag\n",
    "\n",
    "<h3>Tag Identifiers:</h3>\n",
    "\n",
    "<b>class</b> â€”  One element can have multiple classes, and a class can be shared between elements<br>\n",
    "<b>id</b> â€” Each element can only have one id, and an id can only be used once on a page\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/5/55/HTML_element_structure.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2> \n",
    "    <img src=\"https://image.flaticon.com/icons/svg/138/138807.svg\" width=50/>\n",
    "    Requests Library \n",
    "</h2>\n",
    "<hr>\n",
    "The first step in scraping a web page is retrieving the web page.  We can do this with the requests library.  The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://www.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "After running our request, we get a `Response` object. This object has a status_code property, which indicates if the page was downloaded successfully\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "A few possible responses:<br>\n",
    "200 <b>OK</b> - The resource has been fetched and is transmitted in the message body.<br>\n",
    "400 <b>Bad Request</b> - This response means that server could not understand the request due to invalid syntax.<br>\n",
    "500 <b>Internal Server Error</b> The server has encountered a situation it doesn't know how to handle.<br>\n",
    "\n",
    "We can print the HTML of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2> \n",
    "    <img src=\"https://image.flaticon.com/icons/svg/889/889705.svg\" width=50/>\n",
    "    Beautiful Soup Library \n",
    "</h2>\n",
    "<hr>\n",
    "Now that we have the raw HTML, we can use what we can start parsing with our Soup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_page = '''<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"test1\">Here's a paragraph of text!</p>\n",
    "        <p class=\"test2\">Here's a second paragraph of text!</p>\n",
    "    </body>\n",
    "</html>'''\n",
    "#http://htmlpreview.github.io/?https://github.com/brianlau336/BeautifulSoupForTheSoul/blob/master/example_page1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(example_page, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in soup.children] #list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(item) for item in list(soup.children)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3> Find All Tags </h3>\n",
    "Okay, now that was somewhat painful.  Thankfully, we don't have to manually drill down like that every time.  If we want to extract a single tag, we can use the find_all method which will find all the instances of the tag on the page and return a list.\n",
    "<br>\n",
    "<br>\n",
    "![](https://github.com/brianlau336/BeautifulSoupForTheSoul/blob/master/pic2.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('p'):\n",
    "    print (x.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "If you instead only want to find the first instance of a tag, you can use the find method, which will return a single `BeautifulSoup` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3> Searching By Genealogy/Relations </h3>\n",
    "The Beautiful Soup API defines ten other methods for searching the tree, but donâ€™t be afraid! Five of these methods are basically the same as find_all(), and the other five are basically the same as find(). The only differences are in what parts of the tree they search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_p = soup.find('p')\n",
    "first_p.find_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_p = soup.find('p')\n",
    "first_p.find_next_sibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3> Searching By Class/Id </h3>\n",
    "Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_page2 = '''<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>A simple example page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <p class=\"inner-text first-item\" id=\"first\">\n",
    "                First paragraph.\n",
    "            </p>\n",
    "            <p class=\"inner-text\">\n",
    "                Second paragraph.\n",
    "            </p>\n",
    "        </div>\n",
    "        <p class=\"outer-text first-item\" id=\"second\">\n",
    "        <b>\n",
    "                First outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "        <p class=\"outer-text\">\n",
    "            <b>\n",
    "                Second outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>'''\n",
    "#http://htmlpreview.github.io/?https://github.com/brianlau336/BeautifulSoupForTheSoul/blob/master/example_page2.html\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(example_page2, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we can use the `find_all` method to search for items by class or by id. In the below example, we'll search for any p tag that has the class outer-text:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p', class_='outer-text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can also search for elements by id:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id=\"first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can also search for items using CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2> \n",
    "    <img src=\"https://image.flaticon.com/icons/svg/214/214363.svg\" width=50>\n",
    "    A Real Life Example - Houston Weather Data\n",
    "</h2>\n",
    "<hr>\n",
    "Let's say you wanted to grab some weather data for Houston, and you couldn't find any viable API's to use.  You stumble across the National Weather Service website and oh look! They have exactly what you want.  Time to flex those scraping skills.\n",
    "<br>\n",
    "<br>\n",
    "![](https://github.com/brianlau336/BeautifulSoupForTheSoul/blob/master/pic3.jpeg?raw=true)",
    "\n",
    "<b>Houston Weather:</b>\n",
    "https://forecast.weather.gov/MapClick.php?lat=29.7606&lon=-95.3697"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1: Download the web page containing the forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=29.7606&lon=-95.3697\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2: Find the div with id \"seven-day-forecast\", and assign it to week_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_forecast = soup.find(id=\"seven-day-forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 3: Inside week_forecast, find each individual forecast item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_items = week_forecast.find_all(class_=\"tombstone-container\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 4: Extract and print the first forecast item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Okay cool, that forecast item (day) we drilled down into has everything we want!  \n",
    "Looking at what we have, we can extract 4 major data points:\n",
    "\n",
    "1. The name of the forecast item under \"period-name\" class<br>\n",
    "2. The description of the conditions within the \"title\" property of img. This is a little different so we'll come back to it later.<br>\n",
    "3. A short description of the conditions under \"short-desc\" class<br>\n",
    "4. The temperature low under \"temp\" class<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we can extract the \"title\" attribute from the img tag. To do this, we just treat the BeautifulSoup object like a dictionary, and pass in the attribute we want as a key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we know how to extract each individual piece of information, we can combine our knowledge with css selectors and lists to extract everything at once.\n",
    "\n",
    "So let's select all items with the class period-name inside an item with the class tombstone-container in seven_day.\n",
    "We can use list comprehension to call the get_text method on each BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_tags = week_forecast.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.get_text() for sd in week_forecast.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in week_forecast.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in week_forecast.select(\".tombstone-container img\")]\n",
    "\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>\n",
    "    <img src=\"https://image.flaticon.com/icons/svg/185/185816.svg\" width=50>\n",
    "    Pandas!\n",
    "</h2>\n",
    "<hr>\n",
    "Okay, so we have a bunch of lists with data...hm...does this look <i>familiar</i>? \n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"https://confluence.uk.jpmorgan.com/confluence/download/attachments/726254563/PandaMan2.jpeg?version=1&modificationDate=1529014241000&api=v2\">\n",
    "</center>\n",
    "\n",
    "We can now combine the data into a Pandas `DataFrame` and analyze it.\n",
    "\n",
    "In order to do this, we'll call the `DataFrame` class, and pass in each list of items that we have. We pass them in as part of a dictionary. Each dictionary key will become a column in the DataFrame, and each list will become the values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "        \"period\": periods, \n",
    "        \"short_desc\": short_descs, \n",
    "        \"temp\": temps, \n",
    "        \"desc\":descs\n",
    "    })\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can now do some analysis on the data. For example, we can use a regular expression and the Series.str.extract method to pull out the numeric temperature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>\\d+)\")\n",
    "weather[\"temp_num\"] = temp_nums.astype('int')\n",
    "temp_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "We could then find the mean of all the high and low temperatures:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"temp_num\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "We could also only select the rows that happen at night:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_night = weather[\"temp\"].str.contains(\"Low\")\n",
    "weather[\"is_night\"] = is_night\n",
    "is_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[is_night]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>\n",
    "    <img src=\"https://image.flaticon.com/icons/svg/497/497738.svg\" width=50>\n",
    "    Conclusion\n",
    "</h2>\n",
    "<hr>\n",
    "\n",
    "We've only scratched the tip of the iceberg with this walkthrough and real world example.  Imagine all the cool things you can now scrape like airline tickets, stock market data, consumer product prices, it's endless!  \n",
    "\n",
    "<b>Warning!</b>  \n",
    "Web scraping had created a bit of a grey area of what is allowed and what is not allowed.\n",
    "\n",
    "1. It's increasingly being used for business purposes to gain a competitive advantage. So there's often a financial motive behind it.\n",
    "2. It's often done in complete disregard of copyright laws and of Terms of Service (ToS).\n",
    "3. It's often done in abusive manners. For example, web scrapers might send much more requests per second than what a human would do, thus causing an unexpected load on websites.\n",
    "4. It can be used to perform prohibited operations on websites, like circumventing the security measures that are put in place to automatically download data, which would otherwise be inaccessible.\n",
    "\n",
    "In 2009 Facebook won one of the first copyright suits against a web scraper.  This laid the groundwork for numerous lawsuits that tie any web scraping with a direct copyright violation and very clear monetary damages.\n",
    "\n",
    "In 2017 Ticketmaster sued Prestige Entertainment, claiming it used computer programs to illegally buy as many as 40 percent of the available seats for performances of \"Hamilton\" in New York and the majority of the tickets Ticketmaster had available for the Mayweather v. Pacquiao fight in Las Vegas two years ago. \n",
    "\n",
    "![](http://www.blacksheepproductions.com/wp-content/uploads/2016/07/with-great-power-comes-great-resposibility.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
